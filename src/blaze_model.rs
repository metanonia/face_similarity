// Copyright (c) 2025 metanonia
//
// This source code is licensed under the MIT License.
// See the LICENSE file in the project root for license terms.

//! # blaze_model
//!
//! This module implements face  detection using the blazeface model via ONNX Runtime.
//! Models: blaze.onnx

use opencv::core::{no_array, AlgorithmHint, Mat, Point2f, Scalar, Size, BORDER_CONSTANT};
use opencv::imgproc;
use opencv::prelude::*;
use std::error::Error;
use opencv::calib3d::{estimate_affine_partial_2d, RANSAC};
use ort::session::Session;
use ort::value::Tensor;

pub struct BlazeFaceModel {
    pub session: Session,
    pub conf_threshold: f32,
    pub iou_threshold: f32,
    pub max_detections: i64,
}

#[derive(Debug, Clone)]
pub struct BlazeFaceDetection {
    pub score: f32,
    pub bbox: opencv::core::Rect,
    pub landmarks: Vec<[f32; 2]>, // 6ê°œì˜ landmarks (left_eye, right_eye, nose, mouth, left_ear, right_ear)
}

impl BlazeFaceModel {
    pub fn new(
        model_path: &str,
        conf_threshold: f32,
        iou_threshold: f32,
        max_detections: i64,
    ) -> Result<Self, Box<dyn Error>> {
        if !std::path::Path::new(model_path).exists() {
            return Err(format!("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {}", model_path).into());
        }

        let session = Session::builder()?
            .with_intra_threads(4)?
            .commit_from_file(model_path)?;

        Ok(Self {
            session,
            conf_threshold,
            iou_threshold,
            max_detections,
        })
    }

    fn preprocess(&self, img: &Mat) -> Result<Tensor<f32>, Box<dyn Error>> {
        // BGR ì´ë¯¸ì§€ë¥¼ RGBë¡œ ë³€í™˜
        let mut rgb = Mat::default();
        imgproc::cvt_color(
            &img,
            &mut rgb,
            imgproc::COLOR_BGR2RGB,
            0,
            AlgorithmHint::ALGO_HINT_DEFAULT,
        )?;

        // 128x128ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        let mut resized = Mat::default();
        imgproc::resize(
            &rgb,
            &mut resized,
            opencv::core::Size::new(128, 128),
            0.0,
            0.0,
            imgproc::INTER_LINEAR,
        )?;

        let height = 128;
        let width = 128;
        let channels = 3;

        // CHW í˜•ì‹ì˜ f32 ë°ì´í„°ë¥¼ Vecë¡œ ë³€í™˜ (ì •ê·œí™” í¬í•¨)
        let mut data = Vec::with_capacity(channels * height * width);

        // (1, 3, 128, 128) í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        for c in 0..3 {
            for y in 0..height {
                for x in 0..width {
                    let pixel = *resized.at_2d::<opencv::core::Vec3b>(y as i32, x as i32)?;
                    // 0-255 ë²”ìœ„ë¥¼ 0.0-1.0ìœ¼ë¡œ ì •ê·œí™”
                    data.push(pixel[c as usize] as f32 / 255.0);
                }
            }
        }

        // [1, 3, 128, 128] shapeìœ¼ë¡œ í…ì„œ ìƒì„±
        let shape = vec![1, 3, 128, 128];
        let tensor = Tensor::<f32>::from_array((shape, data))?;
        Ok(tensor)
    }

    pub fn detect(&mut self, img: &Mat) -> Result<Vec<BlazeFaceDetection>, Box<dyn Error>> {
        let orig_height = img.rows() as f32;
        let orig_width = img.cols() as f32;

        // ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        let image_tensor = self.preprocess(img)?;

        // threshold í…ì„œ ìƒì„±
        let conf_threshold_tensor =
            Tensor::<f32>::from_array((vec![1], vec![self.conf_threshold]))?;
        let iou_threshold_tensor =
            Tensor::<f32>::from_array((vec![1], vec![self.iou_threshold]))?;
        let max_detections_tensor =
            Tensor::<i64>::from_array((vec![1], vec![self.max_detections]))?;

        // ëª¨ë¸ ì¶”ë¡  ì‹¤í–‰
        let outputs = self.session.run(ort::inputs![
        "image" => image_tensor,
        "conf_threshold" => conf_threshold_tensor,
        "iou_threshold" => iou_threshold_tensor,
        "max_detections" => max_detections_tensor
    ])?;

        // ì¶œë ¥ ê°œìˆ˜ í™•ì¸
        if outputs.len() < 1 {
            return Ok(Vec::new());
        }

        let boxes_value = &outputs[0];
        let boxes_shape: Vec<i64> = boxes_value.shape().iter().map(|&x| x as i64).collect();

        let num_faces = if boxes_shape.len() == 3 {
            if boxes_shape[1] == 0 {
                return Ok(Vec::new());
            }
            boxes_shape[1] as usize
        } else if boxes_shape.len() == 2 {
            if boxes_shape[0] == 0 {
                return Ok(Vec::new());
            }
            boxes_shape[0] as usize
        } else {
            return Err(format!("Unexpected boxes shape: {:?}", boxes_shape).into());
        };

        // ë°ì´í„° ì¶”ì¶œ
        let boxes_result = boxes_value.try_extract_tensor::<f32>()?;
        let boxes_data = boxes_result.1;

        // scores ì²˜ë¦¬
        let scores_data = if outputs.len() > 1 {
            let scores_value = &outputs[1];
            let scores_shape: Vec<i64> = scores_value.shape().iter().map(|&x| x as i64).collect();

            let scores_count = if scores_shape.len() == 2 {
                scores_shape[1] as usize
            } else if scores_shape.len() == 1 {
                scores_shape[0] as usize
            } else {
                0
            };

            if scores_count == 0 {
                vec![1.0; num_faces]
            } else if let Ok(result) = scores_value.try_extract_tensor::<f32>() {
                result.1.to_vec()
            } else {
                vec![1.0; num_faces]
            }
        } else {
            vec![1.0; num_faces]
        };

        let mut detections = Vec::new();

        for i in 0..num_faces {
            let box_offset = i * 16;
            if box_offset + 15 >= boxes_data.len() {
                break;
            }

            let score = if i < scores_data.len() {
                scores_data[i]
            } else {
                1.0
            };

            if score < self.conf_threshold {
                continue;
            }

            // BBox ì¶”ì¶œ - í˜•ì‹: [y1, x1, y2, x2] (normalized 0-1)
            let y1_norm = boxes_data[box_offset];
            let x1_norm = boxes_data[box_offset + 1];
            let y2_norm = boxes_data[box_offset + 2];
            let x2_norm = boxes_data[box_offset + 3];

            // ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜
            let x1 = (x1_norm * orig_width).max(0.0) as i32;
            let y1 = (y1_norm * orig_height).max(0.0) as i32;
            let x2 = (x2_norm * orig_width).min(orig_width) as i32;
            let y2 = (y2_norm * orig_height).min(orig_height) as i32;

            let width = x2 - x1;
            let height = y2 - y1;

            if width < 5 || height < 5 {
                continue;
            }

            let bbox = opencv::core::Rect::new(x1, y1, width, height);

            // 6ê°œ ëœë“œë§ˆí¬ ì¶”ì¶œ - í˜•ì‹: [x, y] ìŒ
            let mut landmarks = Vec::new();
            let landmark_indices = [
                (4, 5),   // left_eye
                (6, 7),   // right_eye
                (8, 9),   // nose
                (10, 11), // mouth
                (12, 13), // left_ear
                (14, 15), // right_ear
            ];

            for (x_idx, y_idx) in landmark_indices.iter() {
                let lm_x_norm = boxes_data[box_offset + x_idx];
                let lm_y_norm = boxes_data[box_offset + y_idx];

                landmarks.push([
                    lm_x_norm * orig_width,
                    lm_y_norm * orig_height,
                ]);
            }

            detections.push(BlazeFaceDetection {
                score,
                bbox,
                landmarks,
            });
        }

        Ok(detections)
    }

    /// BlazeFace 6ì  (ì™¼ëˆˆ, ì˜¤ë¥¸ëˆˆ, ì½”, ì…, ì™¼ê·€, ì˜¤ë¥¸ê·€)ì„ ì‚¬ìš©í•œ ì–¼êµ´ ì •ë ¬
    pub fn align_face_6points_procrustes(
        &self,
        img: &Mat,
        detection: &BlazeFaceDetection,
        output_size: i32,
    ) -> Result<Mat, Box<dyn Error>> {
        if detection.landmarks.len() < 6 {
            return Err(
                "Not enough keypoints (need 6: right_eye, left_eye, nose, mouth, right_ear, left_ear)"
                    .into(),
            );
        }

        // ğŸ”¹ ëª¨ë“  ëœë“œë§ˆí¬ ìœ íš¨ì„± ê²€ì¦
        for (i, lm) in detection.landmarks.iter().enumerate() {
            if !lm[0].is_finite() || !lm[1].is_finite() {
                return Err(format!("Landmark {} contains NaN or Inf", i).into());
            }
        }

        // ğŸ”¹ [f32; 2] â†’ Point2f ë³€í™˜ (ëª¨ë“  6ê°œ ì )
        let src_points_vec: Vec<Point2f> = detection
            .landmarks
            .iter()
            .map(|&p| Point2f::new(p[0], p[1]))
            .collect();
        let src_points_mat = Mat::from_slice(&src_points_vec)?;

        // ğŸ”¹ BlazeFace 6ì  ê¸°ì¤€ í‘œì¤€ í…œí”Œë¦¿ (ì •ê·œí™” ì¢Œí‘œ)
        let std_points = vec![
            Point2f::new(0.62, 0.45), // 0: right_eye
            Point2f::new(0.38, 0.45), // 1: left_eye
            Point2f::new(0.50, 0.55), // 2: nose
            Point2f::new(0.50, 0.65), // 3: mouth
            Point2f::new(0.70, 0.50), // 4: right_ear
            Point2f::new(0.30, 0.50), // 5: left_ear
        ];

        // ğŸ”¹ ì¶œë ¥ í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
        let dst_points: Vec<Point2f> = std_points
            .iter()
            .map(|p| Point2f::new(p.x * output_size as f32, p.y * output_size as f32))
            .collect();
        let dst_points_mat = Mat::from_slice(&dst_points)?;

        // ğŸ”¹ find_homography ì‚¬ìš© (6ê°œ ì  ëª¨ë‘ í™œìš©)
        let mut mask = Mat::default();
        let homography = opencv::calib3d::find_homography(
            &src_points_mat,
            &dst_points_mat,
            &mut mask,
            opencv::calib3d::FM_RANSAC,
            4.0, // ransac_reproj_threshold
        )?;

        // ğŸ”¹ ì´ë¯¸ì§€ ì •ë ¬ ì ìš©
        let mut aligned = Mat::default();
        imgproc::warp_perspective(
            img,
            &mut aligned,
            &homography,
            Size::new(output_size, output_size),
            imgproc::INTER_LINEAR,
            BORDER_CONSTANT,
            Scalar::default(),
        )?;

        if aligned.empty() {
            return Err("Aligned image is empty".into());
        }

        Ok(aligned)
    }

    /// ì–¼êµ´ ì •ë ¬ì„ ìœ„í•œ í—¬í¼ ë©”ì„œë“œ
    pub fn align_face(
        &self,
        img: &Mat,
        detection: &BlazeFaceDetection,
        output_size: i32,
    ) -> Result<Mat, Box<dyn Error>> {
        if detection.landmarks.len() < 2 {
            return Err("ëœë“œë§ˆí¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤".into());
        }

        // ğŸ”¹ ëœë“œë§ˆí¬ ê²€ì¦
        for (i, lm) in detection.landmarks.iter().enumerate() {
            if !lm[0].is_finite() || !lm[1].is_finite() {
                return Err(format!("Landmark {} contains NaN or Inf", i).into());
            }
        }

        // ëˆˆ ìœ„ì¹˜
        let left_eye = detection.landmarks[0];
        let right_eye = detection.landmarks[1];

        // ë‘ ëˆˆ ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°
        let dy = right_eye[1] - left_eye[1];
        let dx = right_eye[0] - left_eye[0];
        let angle = dy.atan2(dx).to_degrees();

        // ë‘ ëˆˆì˜ ì¤‘ì‹¬ì 
        let eyes_center_x = (left_eye[0] + right_eye[0]) / 2.0;
        let eyes_center_y = (left_eye[1] + right_eye[1]) / 2.0;

        // ë‘ ëˆˆ ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚°
        let dist = ((dx * dx) + (dy * dy)).sqrt();

        // ëª©í‘œ ëˆˆ ìœ„ì¹˜ ì„¤ì • (ì¶œë ¥ ì´ë¯¸ì§€ ê¸°ì¤€)
        let desired_left_eye_x = output_size as f32 * 0.35;
        let desired_right_eye_x = output_size as f32 * 0.65;
        let desired_eye_y = output_size as f32 * 0.35;

        // ëª©í‘œ ëˆˆ ì‚¬ì´ ê±°ë¦¬
        let desired_dist = desired_right_eye_x - desired_left_eye_x;

        // ìŠ¤ì¼€ì¼ ê³„ì‚°
        let scale = desired_dist / dist;

        if !scale.is_finite() || scale <= 0.0 {
            return Err(format!("Invalid scale: {}", scale).into());
        }

        // íšŒì „ í–‰ë ¬ ìƒì„± (ëˆˆ ì¤‘ì‹¬ ê¸°ì¤€, ê°ë„, ìŠ¤ì¼€ì¼ í¬í•¨)
        let eyes_center = opencv::core::Point2f::new(eyes_center_x, eyes_center_y);
        let mut rot_mat = imgproc::get_rotation_matrix_2d(eyes_center, angle as f64, scale as f64)?;

        // Translation ì¡°ì • (ì–¼êµ´ì„ ì¶œë ¥ ì´ë¯¸ì§€ ì¤‘ì‹¬ìœ¼ë¡œ ì´ë™)
        let tx = output_size as f32 * 0.5;
        let ty = desired_eye_y;

        // rotation matrixì˜ translation ë¶€ë¶„ ìˆ˜ì •
        *rot_mat.at_2d_mut::<f64>(0, 2)? += (tx as f64 - eyes_center_x as f64);
        *rot_mat.at_2d_mut::<f64>(1, 2)? += (ty as f64 - eyes_center_y as f64);

        // ğŸ”¹ ì •ë ¬ëœ ì´ë¯¸ì§€ê°€ ì œëŒ€ë¡œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
        let mut aligned = Mat::default();
        imgproc::warp_affine(
            img,
            &mut aligned,
            &rot_mat,
            opencv::core::Size::new(output_size, output_size),
            imgproc::INTER_LINEAR,
            opencv::core::BORDER_CONSTANT,
            opencv::core::Scalar::default(),
        )?;

        if aligned.empty() {
            return Err("Aligned image is empty".into());
        }

        Ok(aligned)
    }

    pub fn align_face_5points_procrustes(
        &self,
        img: &Mat,
        detection: &BlazeFaceDetection,
        output_size: i32,
    ) -> Result<Mat, Box<dyn Error>> {
        if detection.landmarks.len() < 6 {
            return Err("6ê°œ ëœë“œë§ˆí¬ê°€ í•„ìš”í•©ë‹ˆë‹¤".into());
        }

        // ğŸ”¹ ëª¨ë“  ëœë“œë§ˆí¬ ìœ íš¨ì„± ê²€ì¦
        for (i, lm) in detection.landmarks.iter().enumerate() {
            if !lm[0].is_finite() || !lm[1].is_finite() {
                return Err(format!("Landmark {} contains NaN or Inf", i).into());
            }
        }

        // 5ê°œ ì  ì„ íƒ
        let src_pts = vec![
            opencv::core::Point2f::new(detection.landmarks[0][0], detection.landmarks[0][1]), // left_eye
            opencv::core::Point2f::new(detection.landmarks[1][0], detection.landmarks[1][1]), // right_eye
            opencv::core::Point2f::new(detection.landmarks[2][0], detection.landmarks[2][1]), // nose
            opencv::core::Point2f::new(detection.landmarks[4][0], detection.landmarks[4][1]), // left_ear
            opencv::core::Point2f::new(detection.landmarks[5][0], detection.landmarks[5][1]), // right_ear
        ];

        // í‘œì¤€ ì¢Œí‘œ (224x224 ê¸°ì¤€)
        let template_landmarks_224 = vec![
            (30.2946, 51.6963),   // left_eye
            (65.5318, 51.5014),   // right_eye
            (48.0252, 71.7366),   // nose
            (15.0, 65.0),         // left_ear
            (81.0, 65.0),         // right_ear
        ];

        // ë™ì  ìŠ¤ì¼€ì¼ ê³„ì‚°
        let left_eye_x = detection.landmarks[0][0];
        let right_eye_x = detection.landmarks[1][0];
        let actual_eye_dist = (right_eye_x - left_eye_x).abs();

        if actual_eye_dist < 5.0 {
            return Err(format!("Eye distance too small: {}", actual_eye_dist).into());
        }

        let template_eye_dist = 65.5318 - 30.2946;
        let scale = actual_eye_dist / template_eye_dist;

        if !scale.is_finite() || scale <= 0.0 {
            return Err(format!("Invalid scale: {}", scale).into());
        }

        // output_sizeì— ë§ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì •
        let scale_to_output = output_size as f32 / 224.0;
        let mut dst_pts = Vec::new();

        for (x, y) in template_landmarks_224.iter() {
            dst_pts.push(opencv::core::Point2f::new(
                x * scale_to_output,
                y * scale_to_output,
            ));
        }

        // Vec<Point2f>ë¥¼ Matìœ¼ë¡œ ë³€í™˜
        let src_mat = opencv::core::Mat::from_slice(&src_pts)?;
        let dst_mat = opencv::core::Mat::from_slice(&dst_pts)?;

        // ğŸ”¹ ì˜¬ë°”ë¥¸ ì‹œê·¸ë‹ˆì²˜ë¡œ í˜¸ì¶œ
        let mut mask = Mat::default();
        let homography = opencv::calib3d::find_homography(
            &src_mat,
            &dst_mat,
            &mut mask,
            opencv::calib3d::FM_RANSAC,
            4.0,  // ransac_reproj_threshold
        )?;

        // ë³€í™˜ ì ìš©
        let mut aligned = Mat::default();
        opencv::imgproc::warp_perspective(
            img,
            &mut aligned,
            &homography,
            opencv::core::Size::new(output_size, output_size),
            opencv::imgproc::INTER_LINEAR,
            opencv::core::BORDER_CONSTANT,
            opencv::core::Scalar::default(),
        )?;

        if aligned.empty() {
            return Err("Aligned image is empty".into());
        }

        Ok(aligned)
    }


    /// BlazeFace 6-pointë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ ì •ë ¬ (5ì  ê¸°ë°˜)
    pub fn align_face_4points_procrustes(
        &self,
        img: &Mat,
        detection: &BlazeFaceDetection,
        output_size: i32,
    ) -> Result<Mat, Box<dyn Error>> {
        if detection.landmarks.len() < 6 {
            return Err("6ê°œ ëœë“œë§ˆí¬ê°€ í•„ìš”í•©ë‹ˆë‹¤".into());
        }

        // ğŸ”¹ ëª¨ë“  ëœë“œë§ˆí¬ ìœ íš¨ì„± ê²€ì¦
        for (i, lm) in detection.landmarks.iter().enumerate() {
            if !lm[0].is_finite() || !lm[1].is_finite() {
                return Err(format!("Landmark {} contains NaN or Inf", i).into());
            }
        }

        // BlazeFace 6ê°œ ëœë“œë§ˆí¬
        // 0: left_eye, 1: right_eye, 2: nose, 3: mouth, 4: left_ear, 5: right_ear

        // ğŸ”¹ 4ê°œ ì  ì„ íƒ (get_perspective_transformì€ ì •í™•íˆ 4ê°œë§Œ ë°›ìŒ)
        // left_eye, right_eye, left_ear, right_ear (4ê°œ ëª¨ì„œë¦¬)
        let src_pts = vec![
            opencv::core::Point2f::new(detection.landmarks[0][0], detection.landmarks[0][1]), // left_eye
            opencv::core::Point2f::new(detection.landmarks[1][0], detection.landmarks[1][1]), // right_eye
            opencv::core::Point2f::new(detection.landmarks[4][0], detection.landmarks[4][1]), // left_ear
            opencv::core::Point2f::new(detection.landmarks[5][0], detection.landmarks[5][1]), // right_ear
        ];

        // ğŸ”¹ ë™ì  ìŠ¤ì¼€ì¼ ê³„ì‚° (ëˆˆ ì‚¬ì´ ê±°ë¦¬ ê¸°ë°˜)
        let left_eye_x = detection.landmarks[0][0];
        let right_eye_x = detection.landmarks[1][0];
        let actual_eye_dist = (right_eye_x - left_eye_x).abs();

        if actual_eye_dist < 5.0 {
            return Err(format!("Eye distance too small: {}", actual_eye_dist).into());
        }

        let template_eye_dist = 65.5318 - 30.2946; // 35.2372
        let scale = actual_eye_dist / template_eye_dist;

        if !scale.is_finite() || scale <= 0.0 {
            return Err(format!("Invalid scale: {}", scale).into());
        }

        // ğŸ”¹ í‘œì¤€ ì¢Œí‘œ (224x224 ê¸°ì¤€, VGGFace2 í‘œì¤€)
        let template_landmarks_224 = vec![
            (30.2946, 51.6963),   // left_eye
            (65.5318, 51.5014),   // right_eye
            (15.0, 65.0),         // left_ear
            (81.0, 65.0),         // right_ear
        ];

        // output_sizeì— ë§ê²Œ ìŠ¤ì¼€ì¼ ì¡°ì •
        let scale_to_output = output_size as f32 / 224.0;
        let mut dst_pts = Vec::new();

        for (x, y) in template_landmarks_224.iter() {
            dst_pts.push(opencv::core::Point2f::new(
                x * scale_to_output,
                y * scale_to_output,
            ));
        }

        // ğŸ”¹ Vec<Point2f>ë¥¼ Matìœ¼ë¡œ ë³€í™˜ (ì •í™•íˆ 4ê°œ ì )
        let src_mat = opencv::core::Mat::from_slice(&src_pts)?;
        let dst_mat = opencv::core::Mat::from_slice(&dst_pts)?;

        // Perspective ë³€í™˜ í–‰ë ¬ ê³„ì‚° (4ê°œ ì  = ì •í™•í•¨)
        let perspective_matrix = opencv::imgproc::get_perspective_transform(&src_mat, &dst_mat, 0)?;

        // ë³€í™˜ ì ìš©
        let mut aligned = Mat::default();
        opencv::imgproc::warp_perspective(
            img,
            &mut aligned,
            &perspective_matrix,
            opencv::core::Size::new(output_size, output_size),
            opencv::imgproc::INTER_LINEAR,
            opencv::core::BORDER_CONSTANT,
            opencv::core::Scalar::default(),
        )?;

        if aligned.empty() {
            return Err("Aligned image is empty".into());
        }

        Ok(aligned)
    }
}
